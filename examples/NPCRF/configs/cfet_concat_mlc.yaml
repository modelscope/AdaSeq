experiment:
  exp_dir: experiments/
  exp_name: cfet
  seed: 42

task: entity-typing

dataset:
  data_files:
    train: 'https://www.modelscope.cn/api/v1/datasets/izhx404/cfet/repo/files?Revision=master&FilePath=train.json'
    valid: 'https://www.modelscope.cn/api/v1/datasets/izhx404/cfet/repo/files?Revision=master&FilePath=dev.json'
    test: 'https://www.modelscope.cn/api/v1/datasets/izhx404/cfet/repo/files?Revision=master&FilePath=test.json'
  tokenizer: char

preprocessor:
  type: multilabel-concat-typing-preprocessor
  model_dir: sijunhe/nezha-cn-base
  max_length: 500

data_collator: MultiLabelConcatTypingDataCollatorWithPadding

model:
  type: multilabel-concat-typing-model
  encoder:
    model_name_or_path: sijunhe/nezha-cn-base
    drop_special_tokens: false
  word_dropout: 0.1
  decoder:
    type: linear
  loss_function: WBCE
  pos_weight: 2

trainer: typing-trainer

train:
  max_epochs: 50
  dataloader:
    batch_size_per_gpu: 16
  optimizer:
    type: AdamW
    lr: 5.0e-5
  lr_scheduler:
    type: CosineLR  # only support in typing currently
    warmup_rate: 0.1 # when choose concat typing model, default to use cosine_linear_with_warmup
    options:
      by_epoch: false
  hooks:
    - type: "CheckpointHook"
      interval: 100
    - type: "BestCkptSaverHook"
      save_file_name: "best_model.pt"

evaluation:
  dataloader:
    batch_size_per_gpu: 32
  metrics: typing-metric
